{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71dcb33",
   "metadata": {},
   "source": [
    "## Social Media User Behavior Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5fcc63",
   "metadata": {},
   "source": [
    "### Project by:- Ayush Sain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476bf4e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Unsupervised learning helps uncover hidden patterns in data without predefined labels. In this project, we use K-Means clustering to segment social media users based on their digital behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b5148",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Identify distinct user groups from survey data and profile them (e.g., Heavy Users, Casual Browsers, Premium Subscribers, Aware but Distracted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "filename = \"HybridDataset.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "# Drop unnamed index columns if any\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55223980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data inspection\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nSample non-null counts:\")\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e46cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "working = df.copy()\n",
    "def yn_map(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in ['yes','y','true','1']:\n",
    "        return 1\n",
    "    if s in ['no','n','false','0']:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Yes/No conversion\n",
    "for c in working.columns:\n",
    "    vals = working[c].dropna().astype(str).str.lower()\n",
    "    if len(vals) > 0 and (vals.isin(['yes','no']).sum() / len(vals)) > 0.15:\n",
    "        working[c + '_bin'] = working[c].apply(yn_map)\n",
    "\n",
    "\n",
    "# Extract numeric values\n",
    "for c in working.columns:\n",
    "    if working[c].dtype == object:\n",
    "        if working[c].dropna().astype(str).str.contains(r'\\d').any():\n",
    "            coerced = pd.to_numeric(working[c].astype(str).str.extract(r'(\\d+\\.?\\d*)')[0], errors='coerce')\n",
    "            if coerced.notna().sum() > 0:\n",
    "                working[c + '_num'] = coerced\n",
    "    \n",
    "\n",
    "# Multi-select expansion\n",
    "def split_and_clean(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = [p.strip().lower() for p in re.split(r'[;,/|]', str(cell)) if p.strip() != '']\n",
    "    parts2 = []\n",
    "    for p in parts:\n",
    "        parts2 += [x.strip() for x in p.split(',') if x.strip() != '']\n",
    "    return list(dict.fromkeys([p for p in parts2 if p != 'nan']))\n",
    "\n",
    "\n",
    "multiselect_cols = [c for c in working.columns if 'platform' in c.lower() or 'activity' in c.lower()]\n",
    "for c in multiselect_cols:\n",
    "    working[c + '_count'] = working[c].apply(lambda x: len(split_and_clean(x)))\n",
    "    top_vals = pd.Series(sum(working[c].dropna().apply(split_and_clean).tolist(), [])).value_counts().head(8).index.tolist()\n",
    "    for val in top_vals:\n",
    "        safe = re.sub(r'[^0-9a-z]+', '_', val)[:30]\n",
    "        colname = f\"{c}_has_{safe}\"\n",
    "        working[colname] = working[c].apply(lambda x: 1 if val in split_and_clean(x) else 0)\n",
    "\n",
    "\n",
    "# One-hot encoding for small categorical questions\n",
    "single_choice_cols = [c for c in working.columns if working[c].dtype == object and working[c].nunique() < 30]\n",
    "special_exclude = ['description','title','director','cast','country']\n",
    "single_choice_cols = [c for c in single_choice_cols if c.lower() not in special_exclude]\n",
    "for c in single_choice_cols:\n",
    "    top = working[c].value_counts().head(6).index.tolist()\n",
    "    for val in top:\n",
    "        colname = f\"{c}_is_\" + re.sub(r'[^0-9a-z]+', '_', str(val).strip().lower())[:30]\n",
    "        working[colname] = working[c].apply(lambda x: 1 if str(x).strip() == str(val).strip() else 0)\n",
    "\n",
    "\n",
    "# Build feature list\n",
    "num_cols = [c for c in working.columns if working[c].dtype in [np.float64, np.int64]]\n",
    "features = [c for c in working.columns if any(s in c for s in ['_num','_count','_bin','_has_','_is_'])]\n",
    "features = sorted(list(set(features + num_cols)))\n",
    "\n",
    "\n",
    "feat_df = working[features].copy()\n",
    "feat_df = feat_df.dropna(thresh=max(1, int(0.5 * len(features))))\n",
    "feat_df = feat_df.fillna(feat_df.median())\n",
    "print(\"Selected features:\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling & PCA\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(feat_df)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(\"Explained variance by 2 components:\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(np.cumsum(PCA().fit(X).explained_variance_ratio_))\n",
    "plt.xlabel('n components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f31f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering & Model Tuning\n",
    "ks = list(range(2,9))\n",
    "inertias, silhouettes = [], []\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labs = km.fit_predict(X)\n",
    "    inertias.append(km.inertia_)\n",
    "    silhouettes.append(silhouette_score(X, labs) if len(set(labs)) > 1 else np.nan)\n",
    "\n",
    "\n",
    "print(pd.DataFrame({'k': ks, 'inertia': inertias, 'silhouette': silhouettes}))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(ks, inertias, marker='o')\n",
    "plt.title('Elbow plot')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(ks, silhouettes, marker='o')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58363b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model & Visualization\n",
    "best_k = ks[int(np.nanargmax(silhouettes))]\n",
    "print(\"Chosen k:\", best_k)\n",
    "final_km = KMeans(n_clusters=best_k, random_state=42, n_init=20)\n",
    "labels = final_km.fit_predict(X)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "for c in np.unique(labels):\n",
    "    sel = X_pca[labels == c]\n",
    "    plt.scatter(sel[:,0], sel[:,1], s=30, alpha=0.7, label=f'Cluster {c}')\n",
    "centers_pca = pca.transform(final_km.cluster_centers_)\n",
    "plt.scatter(centers_pca[:,0], centers_pca[:,1], s=200, c='black', marker='X')\n",
    "plt.legend()\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title(f'Clusters (k={best_k})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Profiling\n",
    "feat_df['cluster'] = labels\n",
    "feat_df['pca1'] = X_pca[:,0]\n",
    "feat_df['pca2'] = X_pca[:,1]\n",
    "\n",
    "\n",
    "cluster_counts = feat_df['cluster'].value_counts().sort_index()\n",
    "print(\"Cluster sizes:\\n\", cluster_counts)\n",
    "\n",
    "\n",
    "cluster_means = feat_df.groupby('cluster').mean()\n",
    "print(cluster_means.head())\n",
    "\n",
    "\n",
    "global_mean = feat_df.drop(columns=['cluster','pca1','pca2']).mean()\n",
    "top_features = {}\n",
    "for c in sorted(feat_df['cluster'].unique()):\n",
    "    mean_c = feat_df[feat_df['cluster'] == c].drop(columns=['cluster','pca1','pca2']).mean()\n",
    "    diff = (mean_c - global_mean).abs().sort_values(ascending=False).head(8)\n",
    "    top_features[c] = diff.index.tolist()\n",
    "print(\"Top features per cluster:\", top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62daa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "feat_df.to_csv('hybrid_dataset_with_clusters.csv', index=False)\n",
    "cluster_means.to_csv('cluster_profile_means.csv')\n",
    "print(\"Saved outputs: hybrid_dataset_with_clusters.csv, cluster_profile_means.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af84272",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This project successfully grouped survey respondents into meaningful social-media usage clusters. These insights can support:\n",
    "\n",
    "Marketing campaigns (cluster-specific targeting).\n",
    "\n",
    "Product development (features for different user types).\n",
    "\n",
    "Digital wellbeing programs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
